#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å›¾ç‰‡ç›¸ä¼¼åº¦æ£€æµ‹è„šæœ¬
åŸºäºsimilaritiesåº“çš„CLIPæ¨¡å‹å®ç°å›¾ç‰‡ç›¸ä¼¼åº¦è®¡ç®—å’Œç­›é€‰

Requirements:
pip install similarities torch torchvision pillow numpy
"""

import os
import sys
import argparse
from typing import List, Tuple, Dict
import numpy as np
from PIL import Image
import torch

try:
    from similarities import ClipSimilarity
except ImportError:
    print("è¯·å®‰è£…similaritiesåº“ï¼špip install similarities")
    sys.exit(1)

# ==================== é…ç½®åŒºåŸŸ ====================
# åœ¨è¿™é‡Œé¢„è®¾å¸¸ç”¨çš„å›¾ç‰‡è·¯å¾„ï¼Œé¿å…æ¯æ¬¡è¿è¡Œæ—¶æ‰‹åŠ¨è¾“å…¥

# é¢„è®¾è·¯å¾„é…ç½®
# PRESET_PATHS = {
#     # é¢„è®¾çš„å›¾ç‰‡ç›®å½•è·¯å¾„
#     "image_directories": {
#         "default": "./images",  # é»˜è®¤å›¾ç‰‡ç›®å½•
#         "photos": "./photos",  # ç…§ç‰‡ç›®å½•
#         "downloads": "./downloads",  # ä¸‹è½½ç›®å½•
#         "dataset": "./dataset/images",  # æ•°æ®é›†ç›®å½•
#         "test": "./test_images",  # æµ‹è¯•å›¾ç‰‡ç›®å½•
#     },

PRESET_PATHS = {
    # é¢„è®¾çš„å›¾ç‰‡ç›®å½•è·¯å¾„
    "image_directories": {
        "default": "./examples/data/shanqiimage",  # é»˜è®¤å›¾ç‰‡ç›®å½•
        "photos": ".examples/data/shanqiimage",  # ç…§ç‰‡ç›®å½•
        "downloads": "./data",  # ä¸‹è½½ç›®å½•
        "dataset": "./examples/data/shanqiimage",  # æ•°æ®é›†ç›®å½•
        "test": "./examples/data/shanqiimage",  # æµ‹è¯•å›¾ç‰‡ç›®å½•
    },

    # é¢„è®¾çš„ç›®æ ‡å›¾ç‰‡è·¯å¾„
    "target_images": {
        "sample1": "./examples/data/shanqiimage/1-1.jpg",
        "sample2": "/examples/data/shanqiimage/1-2.jpg.png",
        "test_img": "./examples/data/shanqiimage/1-3.jpg",
        "reference": "./examples/data/shanqiimage/1-4.jpg",
    },

    # é¢„è®¾çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„
    "output_files": {
        "default": "./similarity_results.txt",
        "detailed": "./detailed_results.txt",
        "batch": "./batch_results.txt",
    }
}

# é»˜è®¤é…ç½®
DEFAULT_CONFIG = {
    "model_name": "openai/clip-vit-base-patch32",  # é»˜è®¤æ¨¡å‹
    "threshold": 0.9998,  # é»˜è®¤ç›¸ä¼¼åº¦é˜ˆå€¼
    "max_results": None,  # é»˜è®¤æœ€å¤§ç»“æœæ•°
    "batch_mode": False,  # é»˜è®¤éæ‰¹é‡æ¨¡å¼
}


# ==================== é…ç½®åŒºåŸŸç»“æŸ ====================


class ImageSimilarityDetector:
    """å›¾ç‰‡ç›¸ä¼¼åº¦æ£€æµ‹å™¨"""

    def __init__(self, model_name: str = "openai/clip-vit-base-patch32"):
        """
        åˆå§‹åŒ–æ£€æµ‹å™¨

        Args:
            model_name: CLIPæ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨openai/clip-vit-base-patch32
                       ä¹Ÿå¯ä»¥ä½¿ç”¨ä¸­æ–‡æ¨¡å‹ï¼šOFA-Sys/chinese-clip-vit-base-patch16
        """
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_name}")
        try:
            self.model = ClipSimilarity(model_name_or_path=model_name)
            print("æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            sys.exit(1)

    def load_image(self, image_path: str) -> Image.Image:
        """
        åŠ è½½å›¾ç‰‡

        Args:
            image_path: å›¾ç‰‡è·¯å¾„

        Returns:
            PIL Imageå¯¹è±¡
        """
        try:
            image = Image.open(image_path)
            # è½¬æ¢ä¸ºRGBæ¨¡å¼ï¼ˆå¤„ç†RGBAç­‰æ ¼å¼ï¼‰
            if image.mode != 'RGB':
                image = image.convert('RGB')
            return image
        except Exception as e:
            print(f"åŠ è½½å›¾ç‰‡å¤±è´¥ {image_path}: {e}")
            return None

    def get_supported_formats(self) -> List[str]:
        """è·å–æ”¯æŒçš„å›¾ç‰‡æ ¼å¼"""
        return ['.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp']

    def find_images_in_directory(self, directory: str) -> List[str]:
        """
        åœ¨ç›®å½•ä¸­æŸ¥æ‰¾æ‰€æœ‰æ”¯æŒçš„å›¾ç‰‡æ–‡ä»¶

        Args:
            directory: ç›®å½•è·¯å¾„

        Returns:
            å›¾ç‰‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        image_paths = []
        supported_formats = self.get_supported_formats()

        for root, dirs, files in os.walk(directory):
            for file in files:
                if any(file.lower().endswith(fmt) for fmt in supported_formats):
                    image_paths.append(os.path.join(root, file))

        return sorted(image_paths)

    def calculate_similarity(self, image1_path: str, image2_path: str) -> float:
        """
        è®¡ç®—ä¸¤å¼ å›¾ç‰‡çš„ç›¸ä¼¼åº¦

        Args:
            image1_path: ç¬¬ä¸€å¼ å›¾ç‰‡è·¯å¾„
            image2_path: ç¬¬äºŒå¼ å›¾ç‰‡è·¯å¾„

        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•° (0-1ä¹‹é—´ï¼Œ1è¡¨ç¤ºå®Œå…¨ç›¸ä¼¼)
        """
        try:
            similarity_score = self.model.similarity(image1_path, image2_path)
            return float(similarity_score)
        except Exception as e:
            print(f"è®¡ç®—ç›¸ä¼¼åº¦å¤±è´¥ {image1_path} vs {image2_path}: {e}")
            return 0.0

    def find_similar_images(
            self,
            target_image: str,
            candidate_images: List[str],
            threshold: float = 0.9998,
            max_results: int = None
    ) -> List[Tuple[str, float]]:
        """
        æ‰¾å‡ºä¸ç›®æ ‡å›¾ç‰‡ç›¸ä¼¼çš„å›¾ç‰‡

        Args:
            target_image: ç›®æ ‡å›¾ç‰‡è·¯å¾„
            candidate_images: å€™é€‰å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ (0-1ä¹‹é—´)
            max_results: æœ€å¤§è¿”å›ç»“æœæ•°é‡ï¼ŒNoneè¡¨ç¤ºä¸é™åˆ¶

        Returns:
            ç›¸ä¼¼å›¾ç‰‡åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º(å›¾ç‰‡è·¯å¾„, ç›¸ä¼¼åº¦åˆ†æ•°)çš„å…ƒç»„
        """
        print(f"æ­£åœ¨ä¸ç›®æ ‡å›¾ç‰‡æ¯”è¾ƒ: {target_image}")
        print(f"ç›¸ä¼¼åº¦é˜ˆå€¼: {threshold}")
        print(f"å€™é€‰å›¾ç‰‡æ•°é‡: {len(candidate_images)}")

        similar_images = []

        for i, candidate_image in enumerate(candidate_images):
            # è·³è¿‡ç›®æ ‡å›¾ç‰‡æœ¬èº«
            if os.path.abspath(candidate_image) == os.path.abspath(target_image):
                continue

            # æ˜¾ç¤ºè¿›åº¦
            if (i + 1) % 10 == 0 or i == len(candidate_images) - 1:
                print(f"è¿›åº¦: {i + 1}/{len(candidate_images)}")

            similarity_score = self.calculate_similarity(target_image, candidate_image)

            if similarity_score >= threshold:
                similar_images.append((candidate_image, similarity_score))
                print(f"  æ‰¾åˆ°ç›¸ä¼¼å›¾ç‰‡: {candidate_image} (ç›¸ä¼¼åº¦: {similarity_score:.4f})")

        # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº
        similar_images.sort(key=lambda x: x[1], reverse=True)

        # é™åˆ¶è¿”å›ç»“æœæ•°é‡
        if max_results is not None:
            similar_images = similar_images[:max_results]

        return similar_images

    def batch_find_similar_images(
            self,
            images_directory: str,
            threshold: float = 0.9998,
            output_file: str = None
    ) -> Dict[str, List[Tuple[str, float]]]:
        """
        æ‰¹é‡æŸ¥æ‰¾ç›¸ä¼¼å›¾ç‰‡ï¼ˆæ‰¾å‡ºç›®å½•ä¸­æ‰€æœ‰ç›¸äº’ç›¸ä¼¼çš„å›¾ç‰‡å¯¹ï¼‰

        Args:
            images_directory: å›¾ç‰‡ç›®å½•
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰

        Returns:
            å­—å…¸ï¼Œé”®ä¸ºå›¾ç‰‡è·¯å¾„ï¼Œå€¼ä¸ºç›¸ä¼¼å›¾ç‰‡åˆ—è¡¨
        """
        image_paths = self.find_images_in_directory(images_directory)
        print(f"æ‰¾åˆ° {len(image_paths)} å¼ å›¾ç‰‡")

        results = {}
        total_comparisons = len(image_paths) * (len(image_paths) - 1) // 2
        current_comparison = 0

        for i, image1 in enumerate(image_paths):
            similar_to_image1 = []

            for j, image2 in enumerate(image_paths[i + 1:], i + 1):
                current_comparison += 1

                if current_comparison % 50 == 0:
                    print(f"æ‰¹é‡æ¯”è¾ƒè¿›åº¦: {current_comparison}/{total_comparisons}")

                similarity_score = self.calculate_similarity(image1, image2)

                if similarity_score >= threshold:
                    similar_to_image1.append((image2, similarity_score))

                    # åŒæ—¶è®°å½•åå‘å…³ç³»
                    if image2 not in results:
                        results[image2] = []
                    results[image2].append((image1, similarity_score))

            if similar_to_image1:
                results[image1] = similar_to_image1

        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        if output_file:
            self.save_results_to_file(results, output_file)

        return results

    def save_results_to_file(self, results: Dict[str, List[Tuple[str, float]]], output_file: str):
        """
        å°†ç»“æœä¿å­˜åˆ°æ–‡ä»¶

        Args:
            results: ç›¸ä¼¼åº¦æ£€æµ‹ç»“æœ
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write("å›¾ç‰‡ç›¸ä¼¼åº¦æ£€æµ‹ç»“æœ\n")
                f.write("=" * 50 + "\n\n")

                for target_image, similar_images in results.items():
                    f.write(f"ç›®æ ‡å›¾ç‰‡: {target_image}\n")
                    f.write(f"ç›¸ä¼¼å›¾ç‰‡æ•°é‡: {len(similar_images)}\n")

                    for similar_image, score in similar_images:
                        f.write(f"  - {similar_image} (ç›¸ä¼¼åº¦: {score:.4f})\n")
                    f.write("\n")

            print(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

        except Exception as e:
            print(f"ä¿å­˜ç»“æœå¤±è´¥: {e}")


def resolve_preset_path(path_input: str, path_type: str) -> str:
    """
    è§£æé¢„è®¾è·¯å¾„

    Args:
        path_input: ç”¨æˆ·è¾“å…¥çš„è·¯å¾„ï¼ˆå¯èƒ½æ˜¯é¢„è®¾åç§°æˆ–å®é™…è·¯å¾„ï¼‰
        path_type: è·¯å¾„ç±»å‹ ('target_images', 'image_directories', 'output_files')

    Returns:
        è§£æåçš„å®é™…è·¯å¾„
    """
    if not path_input:
        return None

    # å¦‚æœè¾“å…¥çš„æ˜¯é¢„è®¾åç§°ï¼Œåˆ™è¿”å›å¯¹åº”çš„é¢„è®¾è·¯å¾„
    if path_type in PRESET_PATHS and path_input in PRESET_PATHS[path_type]:
        resolved_path = PRESET_PATHS[path_type][path_input]
        print(f"ä½¿ç”¨é¢„è®¾è·¯å¾„ '{path_input}': {resolved_path}")
        return resolved_path

    # å¦åˆ™è¿”å›åŸå§‹è¾“å…¥ï¼ˆå‡è®¾æ˜¯å®é™…è·¯å¾„ï¼‰
    return path_input


def list_preset_paths():
    """æ˜¾ç¤ºæ‰€æœ‰é¢„è®¾è·¯å¾„"""
    print("å¯ç”¨çš„é¢„è®¾è·¯å¾„:")
    print("=" * 50)

    print("\nğŸ“ å›¾ç‰‡ç›®å½• (--directory/-d):")
    for name, path in PRESET_PATHS["image_directories"].items():
        exists = "âœ“" if os.path.exists(path) else "âœ—"
        print(f"  {name:12} -> {path} {exists}")

    print("\nğŸ¯ ç›®æ ‡å›¾ç‰‡ (--target/-t):")
    for name, path in PRESET_PATHS["target_images"].items():
        exists = "âœ“" if os.path.exists(path) else "âœ—"
        print(f"  {name:12} -> {path} {exists}")

    print("\nğŸ“„ è¾“å‡ºæ–‡ä»¶ (--output/-o):")
    for name, path in PRESET_PATHS["output_files"].items():
        print(f"  {name:12} -> {path}")

    print(f"\né»˜è®¤é…ç½®:")
    print(f"  æ¨¡å‹: {DEFAULT_CONFIG['model_name']}")
    print(f"  é˜ˆå€¼: {DEFAULT_CONFIG['threshold']}")
    print(f"  æ‰¹é‡æ¨¡å¼: {DEFAULT_CONFIG['batch_mode']}")


def run_with_preset_config():
    """ä½¿ç”¨é¢„è®¾é…ç½®è¿è¡Œ"""
    print("ä½¿ç”¨é¢„è®¾é…ç½®è¿è¡Œ...")
    print(f"ç›®æ ‡å›¾ç‰‡: {PRESET_PATHS['target_images']['sample1']}")
    print(f"å›¾ç‰‡ç›®å½•: {PRESET_PATHS['image_directories']['default']}")
    print(f"ç›¸ä¼¼åº¦é˜ˆå€¼: {DEFAULT_CONFIG['threshold']}")

    # æ£€æŸ¥é¢„è®¾è·¯å¾„æ˜¯å¦å­˜åœ¨
    target_path = PRESET_PATHS['target_images']['sample1']
    directory_path = PRESET_PATHS['image_directories']['default']

    if not os.path.exists(target_path):
        print(f"è­¦å‘Š: é¢„è®¾ç›®æ ‡å›¾ç‰‡ä¸å­˜åœ¨: {target_path}")
        return False

    if not os.path.exists(directory_path):
        print(f"è­¦å‘Š: é¢„è®¾å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {directory_path}")
        return False

    # ä½¿ç”¨é¢„è®¾é…ç½®è¿è¡Œæ£€æµ‹
    detector = ImageSimilarityDetector(model_name=DEFAULT_CONFIG['model_name'])
    candidate_images = detector.find_images_in_directory(directory_path)

    similar_images = detector.find_similar_images(
        target_image=target_path,
        candidate_images=candidate_images,
        threshold=DEFAULT_CONFIG['threshold'],
        max_results=DEFAULT_CONFIG['max_results']
    )

    # æ‰“å°ç»“æœ
    print(f"\næ£€æµ‹å®Œæˆï¼")
    print(f"æ‰¾åˆ° {len(similar_images)} å¼ ç›¸ä¼¼å›¾ç‰‡:")

    for image_path, score in similar_images:
        print(f"  {image_path} (ç›¸ä¼¼åº¦: {score:.4f})")

    return True


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="å›¾ç‰‡ç›¸ä¼¼åº¦æ£€æµ‹å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨é¢„è®¾è·¯å¾„ç¤ºä¾‹:
  %(prog)s --target sample1 --directory default
  %(prog)s -t sample1 -d photos --output detailed
  %(prog)s --batch -d dataset --output batch

æŸ¥çœ‹é¢„è®¾è·¯å¾„:
  %(prog)s --list-presets

ä½¿ç”¨é»˜è®¤é¢„è®¾é…ç½®:
  %(prog)s --run-preset
        """
    )

    parser.add_argument("--target", "-t", type=str,default='/Users/cloudbai/PycharmProjects/imagesim/similarities/examples/data/shanqiimage/1-1.jpg',
                       help="ç›®æ ‡å›¾ç‰‡è·¯å¾„æˆ–é¢„è®¾åç§° (å¦‚: sample1, test_img)")
    parser.add_argument("--directory", "-d", type=str,default='/Users/cloudbai/PycharmProjects/imagesim/similarities/examples/data/shanqiimage',
                        help="å›¾ç‰‡ç›®å½•è·¯å¾„æˆ–é¢„è®¾åç§° (å¦‚: default, photos, dataset)")
    parser.add_argument("--threshold", "-th", type=float, default=DEFAULT_CONFIG['threshold'],
                        help=f"ç›¸ä¼¼åº¦é˜ˆå€¼ (0-1ä¹‹é—´ï¼Œé»˜è®¤{DEFAULT_CONFIG['threshold']})")
    # parser.add_argument("--max-results", "-m", type=int, default=DEFAULT_CONFIG['max_results'],
    #                     help="æœ€å¤§è¿”å›ç»“æœæ•°é‡")
    parser.add_argument("--max-results", "-m", type=int, default=5,
                        help="æœ€å¤§è¿”å›ç»“æœæ•°é‡")
    parser.add_argument("--output", "-o", type=str, default=None,
                        help="è¾“å‡ºæ–‡ä»¶è·¯å¾„æˆ–é¢„è®¾åç§° (å¦‚: default, detailed, batch)")
    parser.add_argument("--model", type=str, default=DEFAULT_CONFIG['model_name'],
                        help="CLIPæ¨¡å‹åç§°")
    parser.add_argument("--batch", "-b", action="store_true",
                        help="æ‰¹é‡æ¨¡å¼ï¼šæ‰¾å‡ºç›®å½•ä¸­æ‰€æœ‰ç›¸äº’ç›¸ä¼¼çš„å›¾ç‰‡å¯¹")
    parser.add_argument("--list-presets", action="store_true",
                        help="æ˜¾ç¤ºæ‰€æœ‰é¢„è®¾è·¯å¾„")
    parser.add_argument("--run-preset", action="store_true",
                        help="ä½¿ç”¨é»˜è®¤é¢„è®¾é…ç½®è¿è¡Œ")

    args = parser.parse_args()

    # æ˜¾ç¤ºé¢„è®¾è·¯å¾„
    if args.list_presets:
        list_preset_paths()
        return

    # ä½¿ç”¨é¢„è®¾é…ç½®è¿è¡Œ
    if args.run_preset:
        success = run_with_preset_config()
        if not success:
            print("\nè¯·ä¿®æ”¹è„šæœ¬é¡¶éƒ¨çš„PRESET_PATHSé…ç½®ï¼Œè®¾ç½®æ­£ç¡®çš„è·¯å¾„")
        return

    # è§£æé¢„è®¾è·¯å¾„
    target_image = resolve_preset_path(args.target, "target_images")
    images_directory = resolve_preset_path(args.directory, "image_directories")
    output_file = resolve_preset_path(args.output, "output_files")

    # éªŒè¯å‚æ•°
    if not args.batch and not target_image:
        print("é”™è¯¯ï¼šè¯·æŒ‡å®šç›®æ ‡å›¾ç‰‡è·¯å¾„ (--target) æˆ–ä½¿ç”¨æ‰¹é‡æ¨¡å¼ (--batch)")
        print("æç¤ºï¼šä½¿ç”¨ --list-presets æŸ¥çœ‹å¯ç”¨çš„é¢„è®¾è·¯å¾„")
        return

    if not images_directory:
        print("é”™è¯¯ï¼šè¯·æŒ‡å®šå›¾ç‰‡ç›®å½•è·¯å¾„ (--directory)")
        print("æç¤ºï¼šä½¿ç”¨ --list-presets æŸ¥çœ‹å¯ç”¨çš„é¢„è®¾è·¯å¾„")
        return

    if not os.path.exists(images_directory):
        print(f"é”™è¯¯ï¼šç›®å½•ä¸å­˜åœ¨ {images_directory}")
        return

    if target_image and not os.path.exists(target_image):
        print(f"é”™è¯¯ï¼šç›®æ ‡å›¾ç‰‡ä¸å­˜åœ¨ {target_image}")
        return

    # åˆå§‹åŒ–æ£€æµ‹å™¨
    detector = ImageSimilarityDetector(model_name=args.model)

    try:
        if args.batch:
            # æ‰¹é‡æ¨¡å¼
            print("å¼€å§‹æ‰¹é‡ç›¸ä¼¼åº¦æ£€æµ‹...")
            results = detector.batch_find_similar_images(
                images_directory=images_directory,
                threshold=args.threshold,
                output_file=output_file
            )

            # æ‰“å°ç»“æœæ‘˜è¦
            total_similar_pairs = sum(len(similar_images) for similar_images in results.values()) // 2
            print(f"\næ£€æµ‹å®Œæˆï¼")
            print(f"æ‰¾åˆ° {total_similar_pairs} å¯¹ç›¸ä¼¼å›¾ç‰‡")

        else:
            # å•ç›®æ ‡æ¨¡å¼
            candidate_images = detector.find_images_in_directory(images_directory)

            similar_images = detector.find_similar_images(
                target_image=target_image,
                candidate_images=candidate_images,
                threshold=args.threshold,
                max_results=args.max_results
            )

            # æ‰“å°ç»“æœ
            print(f"\næ£€æµ‹å®Œæˆï¼")
            print(f"æ‰¾åˆ° {len(similar_images)} å¼ ç›¸ä¼¼å›¾ç‰‡:")

            for image_path, score in similar_images:
                print(f"  {image_path} (ç›¸ä¼¼åº¦: {score:.4f})")

            # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
            if output_file:
                results = {target_image: similar_images}
                detector.save_results_to_file(results, output_file)

    except KeyboardInterrupt:
        print("\næ£€æµ‹è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"æ£€æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")


if __name__ == "__main__":
    main()

# ä½¿ç”¨ç¤ºä¾‹ï¼š
"""
# 1. æŸ¥çœ‹æ‰€æœ‰é¢„è®¾è·¯å¾„
python image_similarity_detector.py --list-presets

# 2. ä½¿ç”¨é»˜è®¤é¢„è®¾é…ç½®å¿«é€Ÿè¿è¡Œ
python image_similarity_detector.py --run-preset

# 3. ä½¿ç”¨é¢„è®¾è·¯å¾„åç§°ï¼ˆæ¨èï¼‰
python image_similarity_detector.py --target sample1 --directory default
python image_similarity_detector.py -t sample1 -d photos --output detailed

# 4. æ··åˆä½¿ç”¨é¢„è®¾åç§°å’Œå®é™…è·¯å¾„
python image_similarity_detector.py --target sample1 --directory /path/to/actual/dir

# 5. æ‰¹é‡æ¨¡å¼ä½¿ç”¨é¢„è®¾è·¯å¾„
python image_similarity_detector.py --batch --directory dataset --output batch

# 6. ä¼ ç»Ÿæ–¹å¼ï¼ˆä»ç„¶æ”¯æŒï¼‰
python image_similarity_detector.py --target /path/to/target.jpg --directory /path/to/images --threshold 0.8

# ä¿®æ”¹é¢„è®¾é…ç½®ï¼š
# 1. åœ¨è„šæœ¬é¡¶éƒ¨çš„PRESET_PATHSä¸­æ·»åŠ æ‚¨çš„å¸¸ç”¨è·¯å¾„
# 2. åœ¨DEFAULT_CONFIGä¸­ä¿®æ”¹é»˜è®¤å‚æ•°
"""